{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BertaQA Open Instruct Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>bertaqa_en</th>\n",
       "      <th>bertaqa_eu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-2-13b-hf</td>\n",
       "      <td>57.06</td>\n",
       "      <td>38.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-2-70b-hf</td>\n",
       "      <td>63.50</td>\n",
       "      <td>45.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-2-7b-hf</td>\n",
       "      <td>53.01</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta-Llama-3-70B</td>\n",
       "      <td>72.22</td>\n",
       "      <td>69.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta-Llama-3-70B-Instruct</td>\n",
       "      <td>74.56</td>\n",
       "      <td>70.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meta-Llama-3-8B</td>\n",
       "      <td>63.58</td>\n",
       "      <td>52.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>63.86</td>\n",
       "      <td>54.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mistral-7B-v0.1</td>\n",
       "      <td>60.91</td>\n",
       "      <td>44.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mixtral-8x7B-v0.1</td>\n",
       "      <td>70.16</td>\n",
       "      <td>52.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Qwen1.5-14B</td>\n",
       "      <td>60.39</td>\n",
       "      <td>45.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen1.5-72B</td>\n",
       "      <td>69.43</td>\n",
       "      <td>53.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen1.5-7B</td>\n",
       "      <td>57.06</td>\n",
       "      <td>41.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2-72b</td>\n",
       "      <td>73.21</td>\n",
       "      <td>58.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2-72b-Instruct</td>\n",
       "      <td>72.29</td>\n",
       "      <td>57.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2-7B</td>\n",
       "      <td>62.59</td>\n",
       "      <td>47.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>61.73</td>\n",
       "      <td>46.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yi-34B</td>\n",
       "      <td>68.92</td>\n",
       "      <td>50.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yi-6B</td>\n",
       "      <td>58.81</td>\n",
       "      <td>42.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yi-9B</td>\n",
       "      <td>59.52</td>\n",
       "      <td>43.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bloom-7b1</td>\n",
       "      <td>33.62</td>\n",
       "      <td>34.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gemma-2-27b</td>\n",
       "      <td>66.99</td>\n",
       "      <td>61.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>66.11</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gemma-2-9b</td>\n",
       "      <td>65.52</td>\n",
       "      <td>59.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>65.24</td>\n",
       "      <td>59.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gemma-2b</td>\n",
       "      <td>47.20</td>\n",
       "      <td>36.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>61.14</td>\n",
       "      <td>53.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>latxa-13b-v1</td>\n",
       "      <td>61.35</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>latxa-13b-v1.1</td>\n",
       "      <td>62.07</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latxa-70b-v1</td>\n",
       "      <td>65.94</td>\n",
       "      <td>65.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>latxa-70b-v1.1</td>\n",
       "      <td>68.15</td>\n",
       "      <td>68.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>latxa-7b-v1</td>\n",
       "      <td>54.08</td>\n",
       "      <td>50.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>latxa-7b-v1.1</td>\n",
       "      <td>50.50</td>\n",
       "      <td>50.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mGPT-13B</td>\n",
       "      <td>34.88</td>\n",
       "      <td>34.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xglm-7.5B</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Task                      Model  bertaqa_en  bertaqa_eu\n",
       "0                Llama-2-13b-hf       57.06       38.96\n",
       "1                Llama-2-70b-hf       63.50       45.86\n",
       "2                 Llama-2-7b-hf       53.01       36.00\n",
       "3              Meta-Llama-3-70B       72.22       69.85\n",
       "4     Meta-Llama-3-70B-Instruct       74.56       70.21\n",
       "5               Meta-Llama-3-8B       63.58       52.90\n",
       "6      Meta-Llama-3-8B-Instruct       63.86       54.79\n",
       "7               Mistral-7B-v0.1       60.91       44.22\n",
       "8             Mixtral-8x7B-v0.1       70.16       52.40\n",
       "9                   Qwen1.5-14B       60.39       45.40\n",
       "10                  Qwen1.5-72B       69.43       53.07\n",
       "11                   Qwen1.5-7B       57.06       41.08\n",
       "12                    Qwen2-72b       73.21       58.62\n",
       "13           Qwen2-72b-Instruct       72.29       57.95\n",
       "14                     Qwen2-7B       62.59       47.39\n",
       "15            Qwen2-7B-Instruct       61.73       46.91\n",
       "16                       Yi-34B       68.92       50.78\n",
       "17                        Yi-6B       58.81       42.22\n",
       "18                        Yi-9B       59.52       43.73\n",
       "19                    bloom-7b1       33.62       34.31\n",
       "20                  gemma-2-27b       66.99       61.56\n",
       "21               gemma-2-27b-it       66.11       61.00\n",
       "22                   gemma-2-9b       65.52       59.36\n",
       "23                gemma-2-9b-it       65.24       59.04\n",
       "24                     gemma-2b       47.20       36.31\n",
       "25                     gemma-7b       61.14       53.93\n",
       "26                 latxa-13b-v1       61.35       59.95\n",
       "27               latxa-13b-v1.1       62.07       62.87\n",
       "28                 latxa-70b-v1       65.94       65.92\n",
       "29               latxa-70b-v1.1       68.15       68.57\n",
       "30                  latxa-7b-v1       54.08       50.25\n",
       "31                latxa-7b-v1.1       50.50       50.13\n",
       "32                     mGPT-13B       34.88       34.29\n",
       "33                    xglm-7.5B       33.62       33.89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "BASQUE_TASKS = ['bertaqa_eu']\n",
    "ENGLISH_TASKS = ['bertaqa_en']\n",
    "\n",
    "def extract_accuracies(results_dir):\n",
    "    data = []\n",
    "    for root, _, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    content = json.load(f)\n",
    "                    for task, metrics in content.get('results', {}).items():\n",
    "                        acc = metrics.get('acc,none')\n",
    "                        if acc is not None:\n",
    "                            acc = round(acc * 100, 2)  # Multiply by 100 and round to 2 decimal places\n",
    "                            model_name = os.path.basename(root).split('__')[-1]\n",
    "                            data.append({\n",
    "                                'Model': model_name,\n",
    "                                'Task': task,\n",
    "                                'Accuracy': acc\n",
    "                            })\n",
    "    return data\n",
    "\n",
    "def create_comparison_table(data, tasks_filter=None):\n",
    "    df = pd.DataFrame(data)\n",
    "    if tasks_filter is not None:\n",
    "        df = df[df['Task'].isin(tasks_filter)]\n",
    "    comparison_table = df.pivot_table(index=['Model'], columns='Task', values='Accuracy')\n",
    "    comparison_table.reset_index(inplace=True)\n",
    "    return comparison_table\n",
    "\n",
    "def merge_all_tables(tables):\n",
    "    merged_table = pd.concat(tables, ignore_index=True)\n",
    "    return merged_table\n",
    "\n",
    "def main():\n",
    "    results_dir = '../results'\n",
    "    data = extract_accuracies(results_dir)\n",
    "    \n",
    "    # Create separate tables for English and non-English tasks\n",
    "    all_table = create_comparison_table(data, tasks_filter=ENGLISH_TASKS + BASQUE_TASKS)\n",
    "    english_table = create_comparison_table(data, tasks_filter=ENGLISH_TASKS)\n",
    "    basque_table = create_comparison_table(data, tasks_filter=BASQUE_TASKS)\n",
    "    \n",
    "    # merge and display tables\n",
    "    merged_table = merge_all_tables([all_table])\n",
    "    display(all_table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
